generation:
  num_subsamples: 5
  num_demos: 5
  num_prompts_per_subsample: 50
  model:
    name: LLAMA
    batch_size: 500
    modelID: meta-llama/Meta-Llama-3-8B-Instruct
    llama_config:
      temperature: 0.9
      top_k: 50
      top_p: 0.9
      do_sample: True

evaluation:
  method: likelihood
  num_samples: 50
  num_few_shot: 5
  model:
    name: LLAMA
    batch_size: 500
    modelID: meta-llama/Meta-Llama-3-8B-Instruct
    llama_config:
      temperature: 0.7
      top_k: 50
      top_p: 1
      do_sample: True
      max_length: 200
demo:
  model:
    name: LLAMA
    batch_size: 500
    modelID: meta-llama/Meta-Llama-3-8B-Instruct
    llama_config:
      temperature: 0.7
      top_k: 50
      top_p: 0.9
      do_sample: True
      max_length: 200
