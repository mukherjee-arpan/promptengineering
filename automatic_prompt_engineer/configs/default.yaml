generation:
  num_subsamples: 5
  num_demos: 5
  num_prompts_per_subsample: 50
  model:
    name: LLAMA
    batch_size: 500
    modelID: meta-llama/Meta-Llama-3-8B-Instruct
    llama_config:
      temperature: 0.9
      top_k: 50
      top_p: 0.9
      do_sample: True

evaluation:
  method: likelihood
  num_samples: 50
  num_few_shot: 5
  model:
    name: GPT_forward
    batch_size: 500
    gpt_config:
      model: text-davinci-002
      temperature: 0.7
      max_tokens: 200
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
demo:
  model:
  name: LLAMA
  batch_size: 500
  modelID: meta-llama/Meta-Llama-3-8B-Instruct
  llama_config:
    temperature: 0.9
    top_k: 50
    top_p: 0.9
    do_sample: True
    max_length: 200
